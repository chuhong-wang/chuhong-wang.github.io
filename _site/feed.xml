<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-01-30T16:59:20-05:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Chuhong Wang</title><subtitle>Hi! I am Chuhong. I am a research scientist at Toyota Research Institute of North America (TRINA). 
Prior to working at at TRINA, I did my PhD at Johns Hopkins University in computational materials science.
My research is primarily focused on atomistic simulation accelerated by machine learning models,  as well as data-driven materials discovery. </subtitle><author><name>{&quot;avatar&quot;=&gt;&quot;/assets/images/bio-photo.jpg&quot;, &quot;bio&quot;=&gt;&quot;Research Scientist at [TRINA](https://amrd.toyota.com/division/trina/), \n PhD in Computational Materials Science&quot;, &quot;links&quot;=&gt;[{&quot;label&quot;=&gt;&quot;Email&quot;, &quot;icon&quot;=&gt;&quot;fas fa-fw fa-envelope&quot;, &quot;url&quot;=&gt;&quot;https://mailto:chuhongwang@outlook.com&quot;}, {&quot;label&quot;=&gt;&quot;Twitter&quot;, &quot;icon&quot;=&gt;&quot;fab fa-fw fa-twitter&quot;, &quot;url&quot;=&gt;&quot;https://twitter.com/chuhong_wang&quot;}, {&quot;label&quot;=&gt;&quot;GitHub&quot;, &quot;icon&quot;=&gt;&quot;fab fa-fw fa-github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/chuhong-wang&quot;}, {&quot;label&quot;=&gt;&quot;LinkedIn&quot;, &quot;icon&quot;=&gt;&quot;fab fa-fw fa-linkedin&quot;, &quot;url&quot;=&gt;&quot;https://linkedin.com/in/chuhong-wang&quot;}, {&quot;label&quot;=&gt;&quot;Google Scholar&quot;, &quot;icon&quot;=&gt;&quot;fas fa-fw fa-graduation-cap&quot;, &quot;url&quot;=&gt;&quot;https://scholar.google.com/citations?hl=en&amp;user=7z4odtAAAAAJ&amp;view_op=list_works&amp;sortby=pubdate&quot;}]}</name></author><entry><title type="html">CUDA flocking parallelization</title><link href="http://localhost:4000/blog/CUDA-flocking/" rel="alternate" type="text/html" title="CUDA flocking parallelization" /><published>2024-01-23T14:34:30-05:00</published><updated>2024-01-23T14:34:30-05:00</updated><id>http://localhost:4000/blog/CUDA-flocking</id><content type="html" xml:base="http://localhost:4000/blog/CUDA-flocking/">&lt;p&gt;UPenn CIS 565: GPU Programming and Architecture
&lt;a href=&quot;https://github.com/CIS565-Fall-2022/Project1-CUDA-Flocking/blob/main/INSTRUCTION.md&quot;&gt;Project 1 - Flocking&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;boid-simulation&quot;&gt;Boid Simulation&lt;/h3&gt;

&lt;h4 id=&quot;in-case-youre-have-the-same-question-in-mind-&quot;&gt;In case you’re have the same question in mind …&lt;/h4&gt;
&lt;p&gt;Q:  From brute force to pre-processing boids with uniform grid, what is the advantage of &lt;strong&gt;sorting by grid cell index&lt;/strong&gt; strategy? It didn’t come nature to me.&lt;/p&gt;

&lt;p&gt;A:  In order to improve computing efficiency, dividing the space into &lt;strong&gt;uniform grid&lt;/strong&gt; and pre-assigning a grid cell index to each boid is a common approach to reduce the number of neighbor checking.&lt;/p&gt;

&lt;p&gt;(For demonstration purpose, suppose there’re &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N&lt;/code&gt; boids. The space is divided into &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;M&lt;/code&gt; grid cells.)&lt;/p&gt;

&lt;p&gt;To implement the pre-processing, naturally, on &lt;strong&gt;CPU&lt;/strong&gt; I’d allocate a  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gridCellIndexArrary&lt;/code&gt; of size &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N&lt;/code&gt; to store the grid cell index of each boid, and a dynamic array &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;particleIndexArray&lt;/code&gt; for each grid cell, then iterate through each boid and add its index to the corresponding grid cell’s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;particleIndexArray&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;During flocking, for each boid we can obtain which cell it belongs to by &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gridCellIndexArrary&lt;/code&gt; and then the boids enclosed can be accessed by &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;particleIndexArray&lt;/code&gt; in constant time.&lt;/p&gt;

&lt;p&gt;Now we move on to &lt;strong&gt;GPU&lt;/strong&gt;. The seemingly general strategy above is no longer applicable. For the reasons 1) There’s no dynamic array on GPU. 2) potential race condition. Point 1 is straightward. Let me explain a little more on point 2. Suppose we parallelize the strategy above on GPU, each thread is responsible for one boid to add its index to the corresponding grid cell’s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;particleIndexArray&lt;/code&gt;. When two of the boids in the same cell grid are being added to the same &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;particleIndexArray&lt;/code&gt; at the same time, the two corresponding threads might overwrite each other’s results, leading to erroneous record.&lt;/p&gt;

&lt;p&gt;So we need to revise the pre-processing method to avoid 1) using dynamics array 2) letting multiple threads writing to shared memory. One of the viable approaches is by sorting. Same as on CPU, we first allocate a  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gridCellIndexArrary&lt;/code&gt; of size &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N&lt;/code&gt; to store the grid cell index of each boid. Meanwhile, we also allocate a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;particleIndexArray&lt;/code&gt; of size &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N&lt;/code&gt; to store the boid cell index of each boid. Then &lt;strong&gt;sorting by key&lt;/strong&gt; with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gridCellIndexArrary&lt;/code&gt; as key and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;particleIndexArray&lt;/code&gt; as value, we can obtain the start and end boid indices of each grid cell at the junction of blocks of homogeneous values in sorted &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gridCellIndexArrary&lt;/code&gt;. Mapping the boid enclosed in those grid cells during flocking is similar to CPU version.&lt;/p&gt;</content><author><name>{&quot;avatar&quot;=&gt;&quot;/assets/images/bio-photo.jpg&quot;, &quot;bio&quot;=&gt;&quot;Research Scientist at [TRINA](https://amrd.toyota.com/division/trina/), \n PhD in Computational Materials Science&quot;, &quot;links&quot;=&gt;[{&quot;label&quot;=&gt;&quot;Email&quot;, &quot;icon&quot;=&gt;&quot;fas fa-fw fa-envelope&quot;, &quot;url&quot;=&gt;&quot;https://mailto:chuhongwang@outlook.com&quot;}, {&quot;label&quot;=&gt;&quot;Twitter&quot;, &quot;icon&quot;=&gt;&quot;fab fa-fw fa-twitter&quot;, &quot;url&quot;=&gt;&quot;https://twitter.com/chuhong_wang&quot;}, {&quot;label&quot;=&gt;&quot;GitHub&quot;, &quot;icon&quot;=&gt;&quot;fab fa-fw fa-github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/chuhong-wang&quot;}, {&quot;label&quot;=&gt;&quot;LinkedIn&quot;, &quot;icon&quot;=&gt;&quot;fab fa-fw fa-linkedin&quot;, &quot;url&quot;=&gt;&quot;https://linkedin.com/in/chuhong-wang&quot;}, {&quot;label&quot;=&gt;&quot;Google Scholar&quot;, &quot;icon&quot;=&gt;&quot;fas fa-fw fa-graduation-cap&quot;, &quot;url&quot;=&gt;&quot;https://scholar.google.com/citations?hl=en&amp;user=7z4odtAAAAAJ&amp;view_op=list_works&amp;sortby=pubdate&quot;}]}</name></author><category term="blog" /><category term="C++" /><category term="cuda" /><summary type="html">UPenn CIS 565: GPU Programming and Architecture Project 1 - Flocking</summary></entry><entry><title type="html">Welcome to Jekyll!</title><link href="http://localhost:4000/blog/welcome-to-jekyll/" rel="alternate" type="text/html" title="Welcome to Jekyll!" /><published>2019-04-18T15:34:30-04:00</published><updated>2019-04-18T15:34:30-04:00</updated><id>http://localhost:4000/blog/welcome-to-jekyll</id><content type="html" xml:base="http://localhost:4000/blog/welcome-to-jekyll/">&lt;p&gt;&lt;strong&gt;University of Pennsylvania, CIS 565: GPU Programming and Architecture,
Project 1 - Flocking&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;boid-simulation&quot;&gt;Boid Simulation&lt;/h3&gt;

&lt;h4 id=&quot;in-case-youre-have-the-same-question-in-mind-&quot;&gt;In case you’re have the same question in mind …&lt;/h4&gt;
&lt;p&gt;Q:  From brute force to pre-processing boids with uniform grid, what is the advantage of &lt;strong&gt;sorting by grid cell index&lt;/strong&gt; strategy? It didn’t come nature to me.&lt;/p&gt;

&lt;p&gt;A:  In order to improve computing efficiency, dividing the space into &lt;strong&gt;uniform grid&lt;/strong&gt; and pre-assigning a grid cell index to each boid is a common approach to reduce the number of neighbor checking.&lt;/p&gt;

&lt;p&gt;(For demonstration purpose, suppose there’re &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N&lt;/code&gt; boids. The space is divided into &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;M&lt;/code&gt; grid cells.)&lt;/p&gt;

&lt;p&gt;To implement the pre-processing, naturally, on &lt;strong&gt;CPU&lt;/strong&gt; I’d allocate a  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gridCellIndexArrary&lt;/code&gt; of size &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N&lt;/code&gt; to store the grid cell index of each boid, and a dynamic array &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;particleIndexArray&lt;/code&gt; for each grid cell, then iterate through each boid and add its index to the corresponding grid cell’s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;particleIndexArray&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;During flocking, for each boid we can obtain which cell it belongs to by &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gridCellIndexArrary&lt;/code&gt; and then the boids enclosed can be accessed by &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;particleIndexArray&lt;/code&gt; in constant time.&lt;/p&gt;

&lt;p&gt;Now we move on to &lt;strong&gt;GPU&lt;/strong&gt;. The seemingly general strategy above is no longer applicable. For the reasons 1) There’s no dynamic array on GPU. 2) potential race condition. Point 1 is straightward. Let me explain a little more on point 2. Suppose we parallelize the strategy above on GPU, each thread is responsible for one boid to add its index to the corresponding grid cell’s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;particleIndexArray&lt;/code&gt;. When two of the boids in the same cell grid are being added to the same &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;particleIndexArray&lt;/code&gt; at the same time, the two corresponding threads might overwrite each other’s results, leading to erroneous record.&lt;/p&gt;

&lt;p&gt;So we need to revise the pre-processing method to avoid 1) using dynamics array 2) letting multiple threads writing to shared memory. One of the viable approaches is by sorting. Same as on CPU, we first allocate a  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gridCellIndexArrary&lt;/code&gt; of size &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N&lt;/code&gt; to store the grid cell index of each boid. Meanwhile, we also allocate a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;particleIndexArray&lt;/code&gt; of size &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N&lt;/code&gt; to store the boid cell index of each boid. Then &lt;strong&gt;sorting by key&lt;/strong&gt; with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gridCellIndexArrary&lt;/code&gt; as key and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;particleIndexArray&lt;/code&gt; as value, we can obtain the start and end boid indices of each grid cell at the junction of blocks of homogeneous values in sorted &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gridCellIndexArrary&lt;/code&gt;. Mapping the boid enclosed in those grid cells during flocking is similar to CPU version.&lt;/p&gt;</content><author><name>{&quot;avatar&quot;=&gt;&quot;/assets/images/bio-photo.jpg&quot;, &quot;bio&quot;=&gt;&quot;Research Scientist at [TRINA](https://amrd.toyota.com/division/trina/), \n PhD in Computational Materials Science&quot;, &quot;links&quot;=&gt;[{&quot;label&quot;=&gt;&quot;Email&quot;, &quot;icon&quot;=&gt;&quot;fas fa-fw fa-envelope&quot;, &quot;url&quot;=&gt;&quot;https://mailto:chuhongwang@outlook.com&quot;}, {&quot;label&quot;=&gt;&quot;Twitter&quot;, &quot;icon&quot;=&gt;&quot;fab fa-fw fa-twitter&quot;, &quot;url&quot;=&gt;&quot;https://twitter.com/chuhong_wang&quot;}, {&quot;label&quot;=&gt;&quot;GitHub&quot;, &quot;icon&quot;=&gt;&quot;fab fa-fw fa-github&quot;, &quot;url&quot;=&gt;&quot;https://github.com/chuhong-wang&quot;}, {&quot;label&quot;=&gt;&quot;LinkedIn&quot;, &quot;icon&quot;=&gt;&quot;fab fa-fw fa-linkedin&quot;, &quot;url&quot;=&gt;&quot;https://linkedin.com/in/chuhong-wang&quot;}, {&quot;label&quot;=&gt;&quot;Google Scholar&quot;, &quot;icon&quot;=&gt;&quot;fas fa-fw fa-graduation-cap&quot;, &quot;url&quot;=&gt;&quot;https://scholar.google.com/citations?hl=en&amp;user=7z4odtAAAAAJ&amp;view_op=list_works&amp;sortby=pubdate&quot;}]}</name></author><category term="blog" /><category term="coding" /><category term="cuda" /><summary type="html">University of Pennsylvania, CIS 565: GPU Programming and Architecture, Project 1 - Flocking</summary></entry></feed>